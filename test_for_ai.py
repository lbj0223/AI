# ============================================
# é¢˜é•œ AI - æ™ºèƒ½é”™é¢˜å˜å¼ç³»ç»Ÿ (äº‘ç«¯ç»ˆæå…¼å®¹ç‰ˆ)
# ============================================

import os

# ã€å¼ºåˆ¶ã€‘ç¯å¢ƒè·¯å¾„é‡å®šå‘ [cite: 2026-01-31]
os.environ['HOME'] = '/tmp'
os.environ['XDG_CONFIG_HOME'] = '/tmp'
os.environ['XDG_CACHE_HOME'] = '/tmp'

import streamlit as st
from pix2tex.cli import LatexOCR
from PIL import Image
from openai import OpenAI
import json
import psycopg2
from psycopg2.extras import Json
import requests


# ============================================
# 1. æ ¸å¿ƒä¿®å¤ï¼šæ‰‹åŠ¨æ¥ç®¡æ¨¡å‹å¹¶å…¼å®¹ Munch
# ============================================

def ensure_model_files():
    """æ‰‹åŠ¨åŒæ­¥ AI æ¨¡å‹è‡³ /tmp ç›®å½•"""
    base_url = "https://github.com/lukas-blecher/LaTeX-OCR/releases/download/v0.0.1/"
    files = {
        "latest.pth": base_url + "latest.pth",
        "config.json": base_url + "config.json"
    }
    for name, url in files.items():
        path = os.path.join("/tmp", name)
        if not os.path.exists(path):
            with st.spinner(f"æ­£åœ¨åŒæ­¥ AI æ ¸å¿ƒç»„ä»¶ {name} ..."):
                r = requests.get(url, stream=True)
                with open(path, 'wb') as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)


@st.cache_resource
def load_ocr_model():
    # ç¡®ä¿æ–‡ä»¶å­˜åœ¨
    ensure_model_files()

    # ã€å…³é”®æ”¹åŠ¨ã€‘ä½¿ç”¨å­—å…¸(Dict)ä»£æ›¿ Namespaceï¼Œè§£å†³ Munch å¼•èµ·çš„ ValueError
    params = {
        "config": "/tmp/config.json",
        "checkpoint": "/tmp/latest.pth",
        "no_cuda": True,
        "no_gui": True
    }

    # ç›´æ¥ä¼ å…¥å­—å…¸ï¼ŒLatexOCR å†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç†
    return LatexOCR(params)


# ============================================
# 2. æ•°æ®åº“é…ç½® (Neon äº‘ç«¯)
# ============================================

db_config = st.secrets["postgres"]


def get_db_connection():
    return psycopg2.connect(**db_config, sslmode='require')


# ... (save_to_db, fetch_history ç­‰å‡½æ•°ä¿æŒä¸å˜) ...

def save_to_db(latex, ai_data):
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        query = "INSERT INTO error_questions (ocr_latex, analysis, variants) VALUES (%s, %s, %s)"
        cur.execute(query, (latex, Json(ai_data['card']), Json(ai_data['exercises'])))
        conn.commit()
        cur.close();
        conn.close()
        return True
    except Exception as e:
        st.error(f"ä¿å­˜å¤±è´¥: {e}");
        return False


def fetch_history():
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        cur.execute("SELECT id, ocr_latex, created_at FROM error_questions ORDER BY created_at DESC LIMIT 5")
        rows = cur.fetchall()
        cur.close();
        conn.close()
        return rows
    except Exception:
        return []


# ============================================
# 3. é¡µé¢é€»è¾‘ (ä¿æŒåŸæ ·)
# ============================================

st.set_page_config(page_title="é¢˜é•œ AI", layout="wide")
st.title("é¢˜é•œ AI â€”â€” æ™ºèƒ½é”™é¢˜å˜å¼ç³»ç»Ÿ")

with st.sidebar:
    st.header("ğŸ•’ äº‘ç«¯å†å²çœ‹æ¿")
    history = fetch_history()
    if history:
        for row in history:
            with st.expander(f"é¢˜ç›® ID: {row[0]} ({row[2].strftime('%m-%d %H:%M')})"):
                st.latex(row[1])
    else:
        st.write("æš‚æ— å†å²è®°å½•")

col1, col2 = st.columns([1, 1])
with col1:
    st.header("ğŸ“¸ é”™é¢˜å½•å…¥")
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["png", "jpg", "jpeg"])
    if uploaded_file:
        img = Image.open(uploaded_file)
        st.image(img, use_container_width=True)
        if st.button("å¼€å§‹è¯†åˆ«"):
            with st.spinner("AI æ­£åœ¨è§£æå…¬å¼..."):
                model = load_ocr_model()
                st.session_state.latex_result = model(img)
                st.rerun()

with col2:
    st.header("ğŸ§  æ™ºèƒ½åˆ†æ")
    if 'latex_result' in st.session_state and st.session_state.latex_result:
        st.latex(st.session_state.latex_result)
        if st.button("âœ¨ ç”Ÿæˆå˜å¼"):
            # (DeepSeek è°ƒç”¨é€»è¾‘ä¿æŒä¸å˜...)
            client = OpenAI(api_key=st.secrets["DEEPSEEK_KEY"], base_url="https://api.deepseek.com")
            prompt = f"è¯†åˆ«å‡ºçš„å…¬å¼ä¸ºï¼š{st.session_state.latex_result}ã€‚è¯·æŒ‰JSONæ ¼å¼è¾“å‡ºcardå’Œexercisesã€‚"
            response = client.chat.completions.create(model="deepseek-chat",
                                                      messages=[{"role": "user", "content": prompt}],
                                                      response_format={'type': 'json_object'})
            st.session_state.ai_data = json.loads(response.choices[0].message.content)

if 'ai_data' in st.session_state and st.session_state.ai_data:
    st.divider()
    if st.button("ğŸ’¾ å­˜å…¥äº‘ç«¯é”™é¢˜æœ¬"):
        if save_to_db(st.session_state.latex_result, st.session_state.ai_data):
            st.toast("å…¥åº“æˆåŠŸï¼", icon="âœ…");
            st.balloons()