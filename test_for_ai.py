# ============================================
# é¢˜é•œ AI - æ™ºèƒ½é”™é¢˜å˜å¼ç³»ç»Ÿ (äº‘ç«¯ç»ˆæä¿®æ­£ç‰ˆ)
# å¼€å‘è€…ï¼šLBJ | çŠ¶æ€ï¼šå…¨äº‘ç«¯ç¯å¢ƒé€‚é…
# ============================================

import os

# --- 1. å¼ºåˆ¶æƒé™é‡å®šå‘ (å¿…é¡»æ”¾åœ¨æœ€é¡¶éƒ¨) ---
os.environ['HOME'] = '/tmp'
os.environ['XDG_CONFIG_HOME'] = '/tmp'
os.environ['XDG_CACHE_HOME'] = '/tmp'

import streamlit as st                    
from pix2tex.cli import LatexOCR         
from PIL import Image                    
from openai import OpenAI                
import json                              
import psycopg2                          
from psycopg2.extras import Json         
import requests

# ============================================
# 2. æ ¸å¿ƒä¿®å¤ï¼šç¡¬ç¼–ç é…ç½®ä¸æ ‡å‡†å‚æ•°ç±»
# ============================================

class ModelArgs:
    """æœ€ç¨³å¥çš„å‚æ•°å®¹å™¨ï¼Œç¡®ä¿ vars() å’Œç‚¹è®¿é—®éƒ½èƒ½æˆåŠŸ"""
    def __init__(self):
        self.config = "/tmp/config.yaml"
        self.checkpoint = "/tmp/weights.pth"
        self.resizer = "/tmp/image_resizer.pth"
        self.no_cuda = True
        self.no_gui = True

def ensure_model_files():
    """æ‰‹åŠ¨æ¥ç®¡æ¨¡å‹ä¸‹è½½ï¼Œå¹¶ç”Ÿæˆæœ¬åœ°é…ç½®æ–‡ä»¶"""
    # ç›´æ¥ç¡¬ç¼–ç  YAML é…ç½®å†…å®¹ï¼Œå½»åº•è§£å†³ 404 å¯¼è‡´çš„ ValueError
    config_content = """
gpu: false
backbone:
  type: vit
  args:
    image_size: [224, 224]
    patch_size: 16
    width: 256
    layers: 4
    heads: 8
channels: 1
max_dimensions: [672, 192]
min_dimensions: [32, 32]
temperature: 0.00001
    """
    
    # å†™å…¥é…ç½®æ–‡ä»¶
    with open("/tmp/config.yaml", "w") as f:
        f.write(config_content.strip())

    # ä¸‹è½½æ¨¡å‹æƒé‡
    base_url = "https://github.com/lukas-blecher/LaTeX-OCR/releases/download/v0.0.1/"
    files = {
        "weights.pth": base_url + "weights.pth",
        "image_resizer.pth": base_url + "image_resizer.pth"
    }
    
    for name, url in files.items():
        path = os.path.join("/tmp", name)
        if not os.path.exists(path):
            with st.spinner(f"æ­£åœ¨åŒæ­¥ AI æ ¸å¿ƒç»„ä»¶ {name}..."):
                r = requests.get(url, stream=True)
                if r.status_code == 200:
                    with open(path, 'wb') as f:
                        for chunk in r.iter_content(chunk_size=8192):
                            f.write(chunk)

@st.cache_resource
def load_ocr_model():
    ensure_model_files()
    # ä½¿ç”¨æ ‡å‡†ç±»å®ä¾‹ï¼Œåº“å†…éƒ¨å¯ä»¥å®Œç¾è¯†åˆ« checkpoint å±æ€§
    return LatexOCR(ModelArgs())

# ============================================
# 3. æ•°æ®åº“ä¸ AI é€»è¾‘ (ä¿æŒäº‘ç«¯é…ç½®)
# ============================================

db_config = st.secrets["postgres"] #

def get_db_connection():
    return psycopg2.connect(**db_config, sslmode='require')

def save_to_db(latex, ai_data):
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        query = "INSERT INTO error_questions (ocr_latex, analysis, variants) VALUES (%s, %s, %s)"
        cur.execute(query, (latex, Json(ai_data['card']), Json(ai_data['exercises'])))
        conn.commit()
        cur.close(); conn.close()
        return True
    except Exception as e:
        st.error(f"ä¿å­˜å¤±è´¥: {e}"); return False

def fetch_history():
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        cur.execute("SELECT id, ocr_latex, created_at FROM error_questions ORDER BY created_at DESC LIMIT 5")
        rows = cur.fetchall()
        cur.close(); conn.close()
        return rows
    except Exception: return []

# ============================================
# 4. ç•Œé¢å¸ƒå±€
# ============================================

st.set_page_config(page_title="é¢˜é•œ AI", layout="wide")
st.title("é¢˜é•œ AI â€”â€” æ™ºèƒ½é”™é¢˜å˜å¼ç³»ç»Ÿ")

with st.sidebar:
    st.header("ğŸ•’ äº‘ç«¯å†å²çœ‹æ¿")
    history = fetch_history()
    if history:
        for row in history:
            with st.expander(f"é¢˜ç›® ID: {row[0]} ({row[2].strftime('%m-%d %H:%M')})"):
                st.latex(row[1])
    else:
        st.write("æš‚æ— å†å²è®°å½•")

col1, col2 = st.columns([1, 1])

with col1:
    st.header("ğŸ“¸ é”™é¢˜å½•å…¥")
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡", type=["png", "jpg", "jpeg"])
    if uploaded_file:
        img = Image.open(uploaded_file)
        st.image(img, width=400)
        if st.button("å¼€å§‹è¯†åˆ«"):
            with st.spinner("AI æ­£åœ¨è§£æå…¬å¼..."):
                model = load_ocr_model()
                st.session_state.latex_result = model(img)
                st.rerun()

with col2:
    st.header("ğŸ§  æ™ºèƒ½åˆ†æ")
    if 'latex_result' in st.session_state and st.session_state.latex_result:
        st.latex(st.session_state.latex_result)
        if st.button("âœ¨ æ„å»ºå˜å¼"):
            client = OpenAI(api_key=st.secrets["DEEPSEEK_KEY"], base_url="https://api.deepseek.com")
            prompt = f"å…¬å¼ï¼š{st.session_state.latex_result}ã€‚è¯·æŒ‰JSONè¾“å‡ºcardå’Œexercisesã€‚"
            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                response_format={'type': 'json_object'}
            )
            st.session_state.ai_data = json.loads(response.choices[0].message.content)

if 'ai_data' in st.session_state and st.session_state.ai_data:
    st.divider()
    if st.button("ğŸ’¾ å­˜å…¥äº‘ç«¯é”™é¢˜æœ¬"):
        if save_to_db(st.session_state.latex_result, st.session_state.ai_data):
            st.toast("å…¥åº“æˆåŠŸï¼", icon="âœ…"); st.balloons()
